---
title: "Machine Learning 2"
---

## Practical Machine Learning with R and mlr3

The mlr3 R package is a modern, object-oriented machine learning framework in R
that builds on the success of its predecessor, the mlr package. It provides a
flexible and extensible platform for handling common machine learning tasks
such as data preprocessing, model training, hyperparameter tuning, and model
evaluation @fig-mlr3-ecosystem. The package is designed to simplify the process of creating and
deploying complex machine learning pipelines.

```{r fig-mlr3-ecosystem, echo=FALSE, fig.cap='The mlr3 ecosystem.', dpi=100}
knitr::include_graphics("images/mlr3_ecosystem.png")
```

### Key features of mlr3

* Task abstraction 
  : mlr3 encapsulates different types of learning problems
  like classification, regression, and survival analysis into "Task" objects,
  making it easier to handle various learning scenarios.
* Modular design
  : The package follows a modular design, allowing users to quickly swap out
  different components such as learners (algorithms), measures (performance
  metrics), and resampling strategies.
* Extensibility
  : Users can extend the functionality of mlr3 by adding custom components like
  learners, measures, and preprocessing steps via the R6 object-oriented
  system.
* Preprocessing
  : mlr3 provides a flexible way to preprocess data using "PipeOps" (pipeline
  operations), allowing users to create reusable preprocessing pipelines.
* Tuning and model selection
  : mlr3 supports hyperparameter tuning and model selection using various
  search strategies like grid search, random search, and Bayesian optimization.
* Parallelization
  : The package allows for parallelization of model training and evaluation,
  making it suitable for large-scale machine learning tasks.
* Benchmarking
  : mlr3 facilitates benchmarking of multiple algorithms on multiple tasks,
  simplifying the process of comparing and selecting the best models.

You can find more information, including tutorials and examples, on the
official mlr3 GitHub repository^[<https://github.com/mlr-org/mlr3>] and the mlr3
book^[<https://mlr3book.mlr-org.com/>].


## The mlr3 workflow

The mlr3 package is designed to simplify the process of creating and deploying
complex machine learning pipelines. The package follows a modular design, which
means that users can quickly swap out different components such as learners
(algorithms), measures (performance metrics), and resampling strategies. The
package also supports parallelization of model training and evaluation, making
it suitable for large-scale machine learning tasks.

The mlr3 workflow consists of the following steps:


1. Load data
1. Create a task to define the learning problem.
1. Split data into training and test sets.
1. Choose a learner object to specify the learning algorithm.
   a. Train the model on the training set.
   b. Predict the target variable for the test set.
1. Assess the performance of the model.
1. Interpret the model.

The following sections describe each of these steps in detail.

### Tasks

Tasks are objects that contain the (usually tabular) data and additional
metadata to define a machine learning problem. The meta-data is, for example,
the name of the target variable for supervised machine learning problems, or
the type of the dataset (e.g. a spatial or survival task). This information is
used by specific operations that can be performed on a task.

Tasks are objects that contain the (usually tabular) data and additional
meta-data to define a machine learning problem. The meta-data is, for example,
the name of the target variable for supervised machine learning problems, or
the type of the dataset (e.g. a _spatial_ or _survival_ task). This information
is used by specific operations that can be performed on a task.

There are a number of [Task Types](https://mlr3book.mlr-org.com/02-basics-tasks.html#tasks-types) that 
are supported by mlr3. To create a task from a [`data.frame()`](https://www.rdocumentation.org/packages/base/topics/data.frame), [`data.table()`](https://www.rdocumentation.org/packages/data.table/topics/data.table-package) or [`Matrix()`](https://www.rdocumentation.org/packages/Matrix/topics/Matrix), you first need to select the right task type:

-   **Classification Task**: The target is a label (stored as `character` or `factor`) with only relatively few distinct values → [`TaskClassif`](https://mlr3.mlr-org.com/reference/TaskClassif.html).
    
-   **Regression Task**: The target is a numeric quantity (stored as `integer` or `numeric`) → [`TaskRegr`](https://mlr3.mlr-org.com/reference/TaskRegr.html).
    
-   **Survival Task**: The target is the (right-censored) time to an event. More censoring types are currently in development → [`mlr3proba::TaskSurv`](https://mlr3proba.mlr-org.com/reference/TaskSurv.html) in add-on package [mlr3proba](https://mlr3proba.mlr-org.com/).
    
-   **Density Task**: An unsupervised task to estimate the density → [`mlr3proba::TaskDens`](https://mlr3proba.mlr-org.com/reference/TaskDens.html) in add-on package [mlr3proba](https://mlr3proba.mlr-org.com/).
    
-   **Cluster Task**: An unsupervised task type; there is no target and the aim is to identify similar groups within the feature space → [`mlr3cluster::TaskClust`](https://mlr3cluster.mlr-org.com/reference/TaskClust.html) in add-on package [mlr3cluster](https://mlr3cluster.mlr-org.com/).
    
-   **Spatial Task**: Observations in the task have spatio-temporal information (e.g. coordinates) → [`mlr3spatiotempcv::TaskRegrST`](https://mlr3spatiotempcv.mlr-org.com/reference/TaskRegrST.html) or [`mlr3spatiotempcv::TaskClassifST`](https://mlr3spatiotempcv.mlr-org.com/reference/TaskClassifST.html) in add-on package [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com/).
    
-   **Ordinal Regression Task**: The target is ordinal → `TaskOrdinal` in add-on package [mlr3ordinal](https://github.com/mlr-org/mlr3ordinal) (still in development).

### Learners

Objects of class [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) provide a unified interface to many popular machine learning algorithms in R. They consist of methods to train and predict a model for a [`Task`](https://mlr3.mlr-org.com/reference/Task.html) and provide meta-information about the learners, such as the hyperparameters (which control the behavior of the learner) you can set.

The base class of each learner is [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html), specialized for regression as [`LearnerRegr`](https://mlr3.mlr-org.com/reference/LearnerRegr.html) and for classification as [`LearnerClassif`](https://mlr3.mlr-org.com/reference/LearnerClassif.html). Other types of learners, provided by extension packages, also inherit from the [`Learner`](https://mlr3.mlr-org.com/reference/Learner.html) base class, e.g. [`mlr3proba::LearnerSurv`](https://mlr3proba.mlr-org.com/reference/LearnerSurv.html) or [`mlr3cluster::LearnerClust`](https://mlr3cluster.mlr-org.com/reference/LearnerClust.html).

All Learners work in a two-stage procedure:

![Two stages of a learner. Top: data (features and a target) are passed to an (untrained) learner. Bottom: new data are passed to the trained model which makes predictions for the ‘missing’ target column.](images/mlr3_learner_stages.png){#fig-mlr3-learner-stages}

-   **Training stage**: The training data (features and target) is passed to the Learner’s `$train()` function which trains and stores a model, i.e. the relationship of the target and features.
-   **Predict stage**: The new data, usually a different slice of the original data than used for training, is passed to the `$predict()` method of the Learner. The model trained in the first step is used to predict the missing target, e.g. labels for classification problems or the numerical value for regression problems.

There are a number of [predefined learners](https://mlr3book.mlr-org.com/02-basics-learners.html#predefined-learners). The [mlr3](https://mlr3.mlr-org.com/) package ships with the following set of classification and regression learners. We deliberately keep this small to avoid unnecessary dependencies:

-   [`classif.featureless`](https://mlr3.mlr-org.com/reference/mlr_learners_classif.featureless.html): Simple baseline classification learner. The default is to always predict the label that is most frequent in the training set. While this is not very useful by itself, it can be used as a “[fallback learner](https://mlr3book.mlr-org.com/fallback-learners)” to make predictions in case another, more sophisticated, learner failed for some reason.
-   [`regr.featureless`](https://mlr3.mlr-org.com/reference/mlr_learners_regr.featureless.html): Simple baseline regression learner. The default is to always predict the mean of the target in training set. Similar to [`mlr_learners_classif.featureless`](https://mlr3.mlr-org.com/reference/mlr_learners_classif.featureless.html), it makes for a good “[fallback learner](https://mlr3book.mlr-org.com/fallback-learners)”
-   [`classif.rpart`](https://mlr3.mlr-org.com/reference/mlr_learners_classif.rpart.html): Single classification tree from package [rpart](https://cran.r-project.org/package=rpart).
-   [`regr.rpart`](https://mlr3.mlr-org.com/reference/mlr_learners_regr.rpart.html): Single regression tree from package [rpart](https://cran.r-project.org/package=rpart).

This set of baseline learners is usually insufficient for a real data analysis. Thus, we have cherry-picked implementations of the most popular machine learning method and collected them in the [mlr3learners](https://mlr3learners.mlr-org.com/) package:

-   Linear ([`regr.lm`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.lm.html)) and logistic ([`classif.log_reg`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.log_reg.html)) regression
-   Penalized Generalized Linear Models ([`regr.glmnet`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.glmnet.html), [`classif.glmnet`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.glmnet.html)), possibly with built-in optimization of the penalization parameter ([`regr.cv_glmnet`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.cv_glmnet.html), [`classif.cv_glmnet`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.cv_glmnet.html))
-   (Kernelized) k\-Nearest Neighbors regression ([`regr.kknn`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.kknn.html)) and classification ([`classif.kknn`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.kknn.html)).
-   Kriging / Gaussian Process Regression ([`regr.km`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.km.html))
-   Linear ([`classif.lda`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.lda.html)) and Quadratic ([`classif.qda`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.qda.html)) Discriminant Analysis
-   Naive Bayes Classification ([`classif.naive_bayes`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.naive_bayes.html))
-   Support-Vector machines ([`regr.svm`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.svm.html), [`classif.svm`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.svm.html))
-   Gradient Boosting ([`regr.xgboost`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.xgboost.html), [`classif.xgboost`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.xgboost.html))
-   Random Forests for regression and classification ([`regr.ranger`](https://mlr3learners.mlr-org.com/reference/mlr_learners_regr.ranger.html), [`classif.ranger`](https://mlr3learners.mlr-org.com/reference/mlr_learners_classif.ranger.html))

More machine learning methods and alternative implementations are collected in the [mlr3extralearners repository](https://github.com/mlr-org/mlr3extralearners/).

### mlr3 Workflow

1. Load data
2. Split data into training and test sets
3. Create a [task](https://mlr3book.mlr-org.com/02-basics-tasks.html). 
4. Choose a [learner](https://mlr3book.mlr-org.com/02-basics-learners.html). See `mlr_learners`.
5. Train
6. Predict
7. Assess
8. Interpret


## Setup

```{r message=FALSE}
library(mlr3verse)
library(GEOquery)
library(mlr3learners) # for knn
library(ranger) # for randomforest
set.seed(789)
```

## Example 1: cancer types

In this exercise, we will be classifying cancer types based on gene 
expression data. The data we are going to access are from @brouwer-visser_regulatory_2018.


### Data Preparation

Use the [GEOquery] package to fetch data about [GSE103512].


```{r geoquery10, echo=TRUE, cache=TRUE, message=FALSE}
library(GEOquery)
gse = getGEO("GSE103512")[[1]]
```

The first step, a detail, is to convert from the older Bioconductor data structure (GEOquery was written in 2007), the `ExpressionSet`, to the newer `SummarizedExperiment`.

```{r message=FALSE}
library(SummarizedExperiment)
se = as(gse, "SummarizedExperiment")
```

Examine two variables of interest, cancer type and tumor/normal status.

```{r geoquery20,echo=TRUE,cache=TRUE}
with(colData(se),table(`cancer.type.ch1`,`normal.ch1`))
```

Before embarking on a machine learning analysis, we need to make sure that
we understand the data. Things like missing values, outliers, and other
problems can cause problems for machine learning algorithms. 

In R, plotting, summaries, and other exploratory data analysis tools are
available. PCA analysis, clustering, and other methods can also be used
to understand the data. It is worth spending time on this step, as it
can save time later.

### Feature selection and data cleaning

While we could use all genes in the analysis, we will select the most informative genes
using the variance of gene expression across samples. Other methods for feature selection
are available, including those based on correlation with the outcome variable. 


::: {.callout-important}
## Feature selection

Feature selection should be done on the training data only, not the test data to avoid
overfitting. 
:::

Remember that the `apply` function applies a function to each row or column of
a matrix. Here, we apply the `sd` function to each row of the expression matrix
to get a vector of stan

```{r sds,cache=TRUE,echo=TRUE}
sds = apply(assay(se, 'exprs'),1,sd)
## filter out normal tissues
se_small = se[order(sds,decreasing = TRUE)[1:200],
              colData(se)$characteristics_ch1.1=='normal: no']
# remove genes with no gene symbol
se_small = se_small[rowData(se_small)$Gene.Symbol!='',]
```

To make the data easier to work with, we will use the opportunity to 
use one of the rowData columns as the rownames of the data frame.
The `make.names` function is used to make sure that the rownames are
valid R variable names and unique.

```{r}
## convert to matrix for later use
dat = assay(se_small, 'exprs')
rownames(dat) = make.names(rowData(se_small)$Gene.Symbol)
```

We also need to transpose the data so that the rows are the samples and the
columns are the features in order to use the data with mlr3.

```{r}
feat_dat = t(dat)
tumor = data.frame(tumor_type = colData(se_small)$cancer.type.ch1, feat_dat)
```

This is another good time to check the data. Make sure that the data is in the
format that you expect. Check the dimensions, the column names, and the data
types. 


### Creating the "task"

The first step in using mlr3 is to create a [task](https://mlr3book.mlr-org.com/02-basics-tasks.html).
A task is a data set with a target variable. In this case, the target variable
is the cancer type. The mlr3 package provides a function to convert a data frame
into a task. These tasks can be used with any machine learning algorithm in mlr3.

```{r}
tumor$tumor_type = as.factor(tumor$tumor_type)
task = as_task_classif(tumor,target='tumor_type')
```

Here, we randomly divide the data into 2/3 training data and 1/3 test data.


```{r}
set.seed(7)
train_set = sample(task$row_ids, 0.67 * task$nrow)
test_set = setdiff(task$row_ids, train_set)
```

::: {.callout-important}
Training and testing on the same data is a common mistake. We want to test
the model on data that it has not seen before. This is the only way to know
if the model is overfitting.
:::

### K-nearest-neighbor

The first model we will use is the k-nearest-neighbor model. This model
is based on the idea that similar samples have similar outcomes. The
number of neighbors to use is a parameter that can be tuned. We'll use
the default value of 7, but you can try other values to see how they
affect the results. In fact, mlr3 provides the ability to tune parameters
automatically, but we won't cover that here.

#### Create the learner

In mlr3, the machine learning algorithms are called learners. To create
a learner, we use the `lrn` function. The `lrn` function takes the name
of the learner as an argument. The `lrn` function also takes other arguments
that are specific to the learner. In this case, we will use the default
values for the arguments.

```{r}
learner = lrn("classif.kknn")
```

You can get a list of all the learners available in mlr3 by using the `lrn()`
function without any arguments.

```{r}
lrn()
```


#### Train

To train the model, we use the `train` function. The `train` function takes
the task and the row ids of the training data as arguments.

```{r}
learner$train(task, row_ids = train_set)
```

Here, we can look at the trained model:

```{r eval=FALSE}
# output is large, so do this on your own
learner$model
```

#### Predict

Lets use our trained model works to predict the classes of the 
**training** data. Of course, we already know the classes of the
training data, but this is a good way to check that the model
is working as expected. It also gives us a measure of performance
on the training data that we can compare to the test data to 
look for overfitting.

```{r}
pred_train = learner$predict(task, row_ids=train_set)
```

And check on the test data:

```{r}
pred_test = learner$predict(task, row_ids=test_set)
```

#### Assess

In this section, we can look at the accuracy and performance of our model 
on the training data and the test data. We can also look at the confusion
matrix to see which classes are being confused with each other. 

```{r}
pred_train$confusion
```

This is a multi-class confusion matrix. The rows are the true classes and
the columns are the predicted classes. The diagonal shows the number of
samples that were correctly classified. The off-diagonal elements show
the number of samples that were misclassified.

We can also look at the accuracy of the model on the training data and the
test data. The accuracy is the number of correctly classified samples divided
by the total number of samples.

```{r}
measures = msrs(c('classif.acc'))
pred_train$score(measures)
```

```{r}
pred_test$confusion
pred_test$score(measures)
```

Compare the accuracy on the training data to the accuracy on the test data. 
Do you see any evidence of overfitting?

### Classification tree

We are going to use a classification tree to classify the data. A classification
tree is a series of yes/no questions that are used to classify the data. The
questions are based on the features in the data. The classification tree is
built by finding the feature that best separates the data into the different
classes. Then, the data is split based on the value of that feature. The
process is repeated until the data is completely separated into the different
classes.

#### Train

```{r}
# in this case, we want to keep the model
# so we can look at it later
learner = lrn("classif.rpart", keep_model = TRUE)
```

```{r}
learner$train(task, row_ids = train_set)
```

We can take a look at the model.


```{r}
learner$model
```

Decision trees are easy to visualize if they are small. Here, we can see that the tree
is very simple, with only two splits. 

```{r} 
#autoplot(learner)
```
#### Predict

Now that we have trained the model on the _training_ data, we can use it to predict the classes of the training data and the test data. The `$predict` method takes a `task` and
produces a prediction based on the _trained_ model, in this case, called `learner`.

```{r}
pred_train = learner$predict(task, row_ids=train_set)
```

Remember that we split the data into training and test sets. We can use the trained model to predict the classes of the test data. Since the _test_ data was not used to train the model, it is
not "cheating" like what we just did where we did the prediction on the _training_ data.

```{r}
pred_test = learner$predict(task, row_ids=test_set)
```

#### Assess

For classification tasks, we often look at a confusion matrix of the _truth_ vs the _predicted_
classes for the samples. 

::: {.callout-important}
Assessing the performance of a model should **always** be **reported** from assessment 
on an independent test set. 
:::

```{r}
pred_train$confusion
```

* What does this confusion matrix tell you?

We can also ask for several "measures" of the performance of the model. Here, we ask for the accuracy of the model. To get a complete list of measures, use `msr()`.

```{r}
measures = msrs(c('classif.acc'))
pred_train$score(measures)
```
* How does the accuracy compare to the confusion matrix?
* How does this accuracy compare to the accuracy of the k-nearest-neighbor model?
* How about the decision tree model?

```{r}
pred_test$confusion
pred_test$score(measures)
```

* What does the confusion matrix in the _test_ set tell you?
* How do the assessments of the _test_ and _training_ sets differ? 

::: {.callout-tip}
## Overfitting

When the assessment of the test set is worse than the evaluation
of the training set, the model may be _overfit_. How to address
overfitting varies by model type, but it is a sign that you should
pay attention to model selection and parameters.
:::


### RandomForest

```{r}
learner = lrn("classif.ranger", importance = "impurity")
```

#### Train

```{r}
learner$train(task, row_ids = train_set)
```
Again, you can look at the model that was trained.

```{r}
learner$model
```

For more details, the mlr3 random forest approach is based
ont he ranger package. You can look at the ranger documentation.

* What is the OOB error in the output? 

Random forests are a collection of decision trees. Since predictors enter the trees
in a random order, the trees are different from each other. The random forest 
procedure gives us a measure of the "importance" of each variable.

```{r}
head(learner$importance(), 15)
```
More "important" variables are those that are more often used in the trees. 
Are the most important variables the same as the ones that were important
in the decision tree?

If you are interested, look up a few of the important variables in the 
model to see if they make biological sense. 

#### Predict

Again, we can use the trained model to predict the classes of the training data and the test data.

```{r}
pred_train = learner$predict(task, row_ids=train_set)
```

```{r}
pred_test = learner$predict(task, row_ids=test_set)
```

#### Assess

```{r}
pred_train$confusion
```

```{r}
measures = msrs(c('classif.acc'))
pred_train$score(measures)
```

```{r}
pred_test$confusion
pred_test$score(measures)
```

## Exercise: Predicting age from DNA methylation

We will be building a regression model for chronological age prediction, based on DNA methylation. This is based on the work of [Jana Naue et al. 2017](https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub), in which biomarkers are examined to predict the chronological age of humans by analyzing the DNA methylation patterns. Different machine learning algorithms are used in this study to make an age prediction.

It has been recognized that within each individual, the level of [DNA methylation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3174260/) changes with age. This knowledge is used to select useful biomarkers from DNA methylation datasets. The [CpG sites](https://en.wikipedia.org/wiki/CpG_site) with the highest correlation to age are selected as the biomarkers (and therefore features for building a regression model). In this tutorial, specific biomarkers are analyzed by machine learning algorithms to create an age prediction model.

The data are taken from [this tutorial](https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/tutorial.html). 



```{r message=FALSE, warning=FALSE}
library(data.table)
meth_age = rbind(
    fread('https://zenodo.org/record/2545213/files/test_rows_labels.csv'),
    fread('https://zenodo.org/record/2545213/files/train_rows.csv')
)
```

Let's take a quick look at the data.

```{r}
head(meth_age)
```

As before, we create the `task` object, but this time we use `as_task_regr()` to create a regression task.

* Why is this a regression task?

```{r}
task = as_task_regr(meth_age,target = 'Age')
```

```{r}
set.seed(7)
train_set = sample(task$row_ids, 0.67 * task$nrow)
test_set = setdiff(task$row_ids, train_set)
```



### Linear regression

We will start with a simple linear regression model. 

```{r}
learner = lrn("regr.lm")
```
#### Train

```{r}
learner$train(task, row_ids = train_set)
```

When you train a linear regression model, we can evaluate some of the 
diagnostic plots to see if the model is appropriate (@fig-regression-diagnostic).


```{r fig-regression-diagnostic, fig.cap="Regression diagnostic plots. The top left plot shows the residuals vs. fitted values. The top right plot shows the normal Q-Q plot. The bottom left plot shows the scale-location plot. The bottom right plot shows the residuals vs. leverage. "}
par(mfrow=c(2,2))
plot(learner$model)
```

#### Predict

```{r}
pred_train = learner$predict(task, row_ids=train_set)
```

```{r}
pred_test = learner$predict(task, row_ids=test_set)
```

#### Assess

```{r}
pred_train
```

We can plot the relationship between the `truth` and `response`, or predicted
value to see visually how our model performs.

```{r}
library(ggplot2)
ggplot(pred_train,aes(x=truth, y=response)) +
    geom_point() +
    geom_smooth(method='lm')
```

We can use the r-squared of the fit to roughly compare two models. 

```{r}
measures = msrs(c('regr.rsq'))
pred_train$score(measures)
```

```{r}
pred_test
pred_test$score(measures)
```

### Regression tree

```{r}
learner = lrn("regr.rpart", keep_model = TRUE)
```

#### Train

```{r}
learner$train(task, row_ids = train_set)
```

```{r}
learner$model
```

What is odd about using a regression tree here is that we end up with only a few
discrete estimates of age. Each "leaf" has a value. 

#### Predict

```{r}
pred_train = learner$predict(task, row_ids=train_set)
```

```{r}
pred_test = learner$predict(task, row_ids=test_set)
```

#### Assess

```{r}
pred_train
```

We can see the effect of the discrete values much more clearly here. 

```{r}
library(ggplot2)
ggplot(pred_train,aes(x=truth, y=response)) +
    geom_point() +
    geom_smooth(method='lm')
```

And the r-squared values for this model prediction shows quite a bit of difference
from the linear regression above. 

```{r}
measures = msrs(c('regr.rsq'))
pred_train$score(measures)
```

```{r}
pred_test
pred_test$score(measures)
```

### RandomForest

Randomforest is also tree-based, but unlike the single regression tree above,
randomforest is a "forest" of trees which will eliminate the discrete nature
of a single tree. 

```{r}
learner = lrn("regr.ranger", mtry=2, min.node.size=20)
```

#### Train

```{r}
learner$train(task, row_ids = train_set)
```

```{r}
learner$model
```

#### Predict

```{r}
pred_train = learner$predict(task, row_ids=train_set)
```

```{r}
pred_test = learner$predict(task, row_ids=test_set)
```

#### Assess

```{r}
pred_train
```

```{r}
ggplot(pred_train,aes(x=truth, y=response)) +
    geom_point() +
    geom_smooth(method='lm')
```

```{r}
measures = msrs(c('regr.rsq'))
pred_train$score(measures)
```

```{r}
pred_test
pred_test$score(measures)
```

## Expression prediction from histone modification data

In this little set of exercises, you will be using histone marks near a gene to predict its expression (@fig-gene-expression).

$$y = h1 + h2 + h3 + ...$$ {#eq-1}

![What is the combined effect of histone marks on gene expression?](images/gene_expression_prediction_question.png){#fig-gene-expression}



We will try a couple of different approaches:

1. Penalized regression
2. RandomForest

### The Data

The data in this 

```{r}
fullFeatureSet <- read.table("http://seandavi.github.io/ITR/expression-prediction/features.txt");
```

What are the column names of the predictor variables?

```{r}
colnames(fullFeatureSet)
```

These are going to be predictors combined into a model. Some of our learners will rely on predictors
being on a similar scale. Are our data already there?

To perform centering and scaling by column, we can convert to a matrix and then use `scale`.

```{r fig-scaled-data, fig.cap="Boxplots of original and scaled data."}
par(mfrow=c(1,2))
scaled_features <- scale(as.matrix(fullFeatureSet))
boxplot(fullFeatureSet, title='Original data')
boxplot(scaled_features, title='Centered and scaled data')
```

There is a row for each gene and a column for each histone mark and we can see that the data are
centered and scaled by column. We can also see some patterns in the data (see @fig-heatmap). 

```{r fig-heatmap, fig.cap="Heatmap of 500 randomly sampled rows of the data. Columns are histone marks and there is a row for each gene."}
sampled_features <- fullFeatureSet[sample(nrow(scaled_features), 500),]
library(ComplexHeatmap)
Heatmap(sampled_features, name='histone marks', show_row_names=FALSE)
```

Now, we can read in the associated gene expression measures that will become
our "target" for prediction.

```{r}
target <- scan(url("http://seandavi.github.io/ITR/expression-prediction/target.txt"), skip=1)
# make into a dataframe
exp_pred_data <- data.frame(gene_expression=target, scaled_features)
```

And the first few rows of the target data frame using:
```{r}
head(exp_pred_data,3)
```

### Create task

```{r}
exp_pred_task = as_task_regr(exp_pred_data, target='gene_expression')
```

Partition the data into test and training sets. We will use $\frac{1}{3}$ and $\frac{2}{3}$ of the data for testing.

```{r}
split = partition(exp_pred_task)
```

### Linear regression

```{r}
learner = lrn("regr.lm")
```

#### Train

```{r}
learner$train(exp_pred_task, split$train)
```

#### Predict

```{r}
pred_train = learner$predict(exp_pred_task, split$train)
pred_test = learner$predict(exp_pred_task, split$test)
```

#### Assess

```{r}
pred_train
```

For the training data:

```{r}
measures = msrs(c('regr.rsq'))
pred_train$score(measures)
```

And the test data:

```{r}
pred_test$score(measures)
```


### Penalized regression

Recall that we can use penalized regression to select the most important
predictors from a large set of predictors. In this case, we will use the
`glmnet` package to perform penalized regression, but we will use the
`mlr` interface to `glmnet` to make it easier to use.

```{r}
learner = lrn("regr.cv_glmnet", nfolds=10, alpha=1)
```

#### Train

```{r}
learner$train(exp_pred_task)
```

```{r}
measures = msrs(c('regr.rsq'))
pred_train$score(measures)
```

In the case of the penalized regression, we can also look at the coefficients
of the model. 

```{r}
coef(learner$model)
```

Note that the coefficients are all zero for the histone marks that were not
selected by the model. In this case, we can use the model not to predict new
data, but to help us understand the data. 


## Cross-validation


```{r}
as.data.table(mlr_resamplings)
```




